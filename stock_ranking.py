# çµ±åˆæ ªä¾¡ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ï¼ˆWebã‚µãƒ¼ãƒ“ã‚¹ç”¨ï¼‰
# NQ100 + S&P500ä¸¡æ–¹å¯¾å¿œã€JSONå‡ºåŠ›å¯¾å¿œç‰ˆ + å±¥æ­´ç®¡ç†æ©Ÿèƒ½

import pandas as pd
import yfinance as yf
import numpy as np
import json
from datetime import datetime, timedelta
import os
from collections import OrderedDict
import time

def get_nasdaq100_symbols():
    """NASDAQ100éŠ˜æŸ„ã‚’å–å¾—"""
    try:
        Symbol_df = pd.read_html("https://en.wikipedia.org/wiki/Nasdaq-100")[4]
        symbols = Symbol_df.Ticker.to_list()
        print(f"NASDAQ100å–å¾—å®Œäº†: {len(symbols)}éŠ˜æŸ„")
        return symbols, "NASDAQ-100"
    except Exception as e:
        print(f"NASDAQ100å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        fallback = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'META', 'TSLA', 'NFLX', 'ADBE', 'CRM']
        print(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨: {len(fallback)}éŠ˜æŸ„")
        return fallback, "NASDAQ-100"

def get_sp500_symbols():
    """S&P500éŠ˜æŸ„ã‚’å–å¾—"""
    try:
        sp500_tables = pd.read_html("https://en.wikipedia.org/wiki/List_of_S%26P_500_companies")
        Symbol_df = sp500_tables[0]
        
        # å•é¡Œã®å¤šã„éŠ˜æŸ„ã‚’äº‹å‰ã«é™¤å¤–
        problematic_tickers = ['BRK.B', 'BF.B']
        symbols = [ticker for ticker in Symbol_df['Symbol'].tolist() if ticker not in problematic_tickers]
        print(f"S&P500å–å¾—å®Œäº†: {len(symbols)}éŠ˜æŸ„ (å•é¡ŒéŠ˜æŸ„{len(problematic_tickers)}å€‹é™¤å¤–)")
        return symbols, "S&P 500"
    except Exception as e:
        print(f"S&P500å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        fallback = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'BRK-B', 'UNH', 'JNJ', 'V', 'XOM', 'PG']
        print(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨: {len(fallback)}éŠ˜æŸ„")
        return fallback, "S&P 500"

def process_stock_data(symbols, index_name):
    """æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ç”Ÿæˆ"""
    if not symbols:
        return None
    
    print(f"\n{index_name} ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–‹å§‹...")
    
    try:
        # S&P500ã®å ´åˆã¯åˆ†å‰²å–å¾—
        if len(symbols) > 200:
            print(f"å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®ãŸã‚åˆ†å‰²å–å¾—: {len(symbols)}éŠ˜æŸ„")
            all_data = []
            batch_size = 100
            
            for i in range(0, len(symbols), batch_size):
                batch_symbols = symbols[i:i+batch_size]
                print(f"ãƒãƒƒãƒ {i//batch_size + 1}: {len(batch_symbols)}éŠ˜æŸ„å–å¾—ä¸­...")
                
                try:
                    batch_df = yf.download(batch_symbols, start='2020-01-01', auto_adjust=False, 
                                         progress=False, threads=True)['Close']
                    if not batch_df.empty:
                        all_data.append(batch_df)
                    time.sleep(1)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
                except Exception as e:
                    print(f"ãƒãƒƒãƒ {i//batch_size + 1} ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
            
            if all_data:
                df = pd.concat(all_data, axis=1)
                print(f"åˆ†å‰²å–å¾—å®Œäº†: {df.shape}")
            else:
                print("ã™ã¹ã¦ã®ãƒãƒƒãƒãŒå¤±æ•—")
                return None
        else:
            # NASDAQ100ãªã©å°‘æ•°ã®å ´åˆã¯é€šå¸¸å–å¾—
            df = yf.download(symbols, start='2020-01-01', auto_adjust=False, progress=False)['Close']
            print(f"ä¸€æ‹¬å–å¾—å®Œäº†: {df.shape}")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        original_count = len(df.columns) if len(df.shape) > 1 else 1
        df = df.dropna(axis=1)
        dropped_count = original_count - (len(df.columns) if len(df.shape) > 1 else 1)
        
        if dropped_count > 0:
            print(f"âš ï¸  {dropped_count}éŠ˜æŸ„ãŒãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚é™¤å¤–")
        
        # æ®‹ã£ãŸéŠ˜æŸ„æ•°ã‚’ç¢ºèª
        remaining_count = len(df.columns) if len(df.shape) > 1 else 1
        print(f"ğŸ“Š å‡¦ç†å¯¾è±¡éŠ˜æŸ„æ•°: {remaining_count}")
        
        if remaining_count < 10:
            print("âš ï¸ å‡¦ç†å¯èƒ½ãªéŠ˜æŸ„ãŒå°‘ãªã™ãã¾ã™")
            return None
        
        print(f"ğŸ“… ãƒ‡ãƒ¼ã‚¿æœŸé–“: {df.index[0]} ï½ {df.index[-1]}")
        print(f"ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {df.shape}")
        
        # æœˆæ¬¡ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—
        try:
            print("ğŸ”„ æœˆæ¬¡ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—ä¸­...")
            mtl = (df.pct_change()+1)[1:].resample('ME').prod()
            print(f"ğŸ“Š æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {mtl.shape}")
            print(f"ğŸ“… æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿æœŸé–“: {mtl.index[0]} ï½ {mtl.index[-1]}")
        except Exception as e:
            print(f"æœˆæ¬¡ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            try:
                mtl = (df.pct_change()+1)[1:].resample('M').prod()
                print(f"ğŸ“Š æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ï¼ˆä»£æ›¿ï¼‰: {mtl.shape}")
            except Exception as e2:
                print(f"ä»£æ›¿æœˆæ¬¡è¨ˆç®—ã‚‚ã‚¨ãƒ©ãƒ¼: {e2}")
                return None
        
        # å„æœŸé–“ã®ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—
        def get_rolling_ret(df, n):
            return df.rolling(n).apply(np.prod)
        
        ret_12 = get_rolling_ret(mtl, 12)
        ret_6 = get_rolling_ret(mtl, 6)
        ret_3 = get_rolling_ret(mtl, 3)
        ret_1 = get_rolling_ret(mtl, 1)
        
        # æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹æ—¥ä»˜ã‚’å–å¾—
        latest_date = mtl.index[-1]
        
        # TOP10ã¨TOP5ã‚’è¨ˆç®—
        def get_top_stocks(date, ret_12, ret_6, ret_3, n_top=10):
            try:
                if ret_12.empty or ret_6.empty or ret_3.empty:
                    print(f"è­¦å‘Š: ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¨ˆç®—ã‚’ã‚¹ã‚­ãƒƒãƒ—")
                    return []
                
                top_50_series = ret_12.loc[date].dropna()
                if len(top_50_series) == 0:
                    print(f"è­¦å‘Š: {date}ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    return []
                
                top_50 = top_50_series.nlargest(min(50, len(top_50_series))).index
                if len(top_50) == 0:
                    return []
                
                top_30_series = ret_6.loc[date, top_50].dropna()
                top_30 = top_30_series.nlargest(min(30, len(top_30_series))).index
                if len(top_30) == 0:
                    return []
                
                top_stocks_series = ret_3.loc[date, top_30].dropna()
                top_stocks = top_stocks_series.nlargest(min(n_top, len(top_stocks_series))).index
                return top_stocks.tolist()
            except Exception as e:
                print(f"ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
                return []
        
        def get_ultra_top_stocks(date, ret_12, ret_6, ret_3, ret_1, n_top=5):
            try:
                if ret_12.empty or ret_6.empty or ret_3.empty or ret_1.empty:
                    print(f"è­¦å‘Š: ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ULTRAãƒ©ãƒ³ã‚­ãƒ³ã‚°è¨ˆç®—ã‚’ã‚¹ã‚­ãƒƒãƒ—")
                    return []
                
                top_50_series = ret_12.loc[date].dropna()
                if len(top_50_series) == 0:
                    return []
                
                top_50 = top_50_series.nlargest(min(50, len(top_50_series))).index
                if len(top_50) == 0:
                    return []
                
                top_30_series = ret_6.loc[date, top_50].dropna()
                top_30 = top_30_series.nlargest(min(30, len(top_30_series))).index
                if len(top_30) == 0:
                    return []
                
                top_10_series = ret_3.loc[date, top_30].dropna()
                top_10 = top_10_series.nlargest(min(10, len(top_10_series))).index
                if len(top_10) == 0:
                    return []
                
                ultra_top_series = ret_1.loc[date, top_10].dropna()
                ultra_top = ultra_top_series.nlargest(min(n_top, len(ultra_top_series))).index
                return ultra_top.tolist()
            except Exception as e:
                print(f"ULTRAãƒ©ãƒ³ã‚­ãƒ³ã‚°è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
                return []
        
        top_10 = get_top_stocks(latest_date, ret_12, ret_6, ret_3, 10)
        ultra_top_5 = get_ultra_top_stocks(latest_date, ret_12, ret_6, ret_3, ret_1, 5)
        
        result = {
            "index_name": index_name,
            "last_updated": latest_date.strftime("%Y-%m-%d"),
            "top_10": top_10,
            "ultra_top_5": ultra_top_5,
            "total_stocks_processed": len(df.columns) if len(df.shape) > 1 else 1
        }
        
        print(f"{index_name} å‡¦ç†å®Œäº†")
        return result
        
    except Exception as e:
        print(f"{index_name} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def load_history():
    """æ—¢å­˜ã®å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    history_file = "data/rankings_history.json"
    
    if os.path.exists(history_file):
        try:
            with open(history_file, "r", encoding="utf-8") as f:
                history = json.load(f)
            print(f"ğŸ“š æ—¢å­˜å±¥æ­´ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(history)}æ—¥åˆ†")
            return history
        except Exception as e:
            print(f"å±¥æ­´ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    else:
        print("ğŸ“š æ–°è¦å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™")
        return {}

def update_history(history, nasdaq_result, sp500_result):
    """å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ï¼ˆéå»30æ—¥åˆ†ã‚’ä¿æŒï¼‰"""
    today = datetime.now().strftime("%Y-%m-%d")
    
    # ä»Šæ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    history[today] = {
        "nasdaq100": {
            "ultra_top_5": nasdaq_result["ultra_top_5"] if nasdaq_result else [],
            "top_10": nasdaq_result["top_10"] if nasdaq_result else []
        },
        "sp500": {
            "ultra_top_5": sp500_result["ultra_top_5"] if sp500_result else [],
            "top_10": sp500_result["top_10"] if sp500_result else []
        }
    }
    
    # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆã—ã€æ–°ã—ã„é †ã«ä¸¦ã¹ã‚‹
    sorted_dates = sorted(history.keys(), reverse=True)
    
    # éå»30æ—¥åˆ†ã®ã¿ä¿æŒ
    if len(sorted_dates) > 30:
        dates_to_keep = sorted_dates[:30]
        history = {date: history[date] for date in dates_to_keep}
        print(f"ğŸ“… å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’30æ—¥åˆ†ã«åˆ¶é™: {len(dates_to_keep)}æ—¥åˆ†ä¿æŒ")
    
    return history

def save_history(history):
    """å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    history_file = "data/rankings_history.json"
    
    try:
        # æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆï¼ˆOrderedDictã‚’ä½¿ç”¨ã—ã¦é †åºã‚’ä¿æŒï¼‰
        sorted_history = OrderedDict(sorted(history.items(), reverse=True))
        
        with open(history_file, "w", encoding="utf-8") as f:
            json.dump(sorted_history, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“š å±¥æ­´ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {len(sorted_history)}æ—¥åˆ†")
        
        # å±¥æ­´ã®çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
        if sorted_history:
            oldest_date = min(sorted_history.keys())
            newest_date = max(sorted_history.keys())
            print(f"ğŸ“Š å±¥æ­´æœŸé–“: {oldest_date} ï½ {newest_date}")
        
    except Exception as e:
        print(f"å±¥æ­´ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

def analyze_ranking_changes(history):
    """ãƒ©ãƒ³ã‚­ãƒ³ã‚°å¤‰å‹•ã‚’åˆ†æï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ï¼‰"""
    if len(history) < 2:
        return
    
    dates = sorted(history.keys(), reverse=True)
    today = dates[0]
    yesterday = dates[1] if len(dates) > 1 else None
    
    if not yesterday:
        return
    
    print(f"\nğŸ“ˆ ãƒ©ãƒ³ã‚­ãƒ³ã‚°å¤‰å‹•åˆ†æ ({yesterday} â†’ {today})")
    print("-" * 50)
    
    # NASDAQ100ã®å¤‰å‹•
    if history[today]["nasdaq100"]["ultra_top_5"] and history[yesterday]["nasdaq100"]["ultra_top_5"]:
        today_nasdaq = history[today]["nasdaq100"]["ultra_top_5"]
        yesterday_nasdaq = history[yesterday]["nasdaq100"]["ultra_top_5"]
        
        print("ğŸŸ¢ NASDAQ100 ULTRA TOP5å¤‰å‹•:")
        for i, (today_stock, yesterday_stock) in enumerate(zip(today_nasdaq, yesterday_nasdaq), 1):
            if today_stock != yesterday_stock:
                print(f"  {i}ä½: {yesterday_stock} â†’ {today_stock} ğŸ”„")
            else:
                print(f"  {i}ä½: {today_stock} (å¤‰å‹•ãªã—)")
    
    # S&P500ã®å¤‰å‹•
    if history[today]["sp500"]["ultra_top_5"] and history[yesterday]["sp500"]["ultra_top_5"]:
        today_sp500 = history[today]["sp500"]["ultra_top_5"]
        yesterday_sp500 = history[yesterday]["sp500"]["ultra_top_5"]
        
        print("\nğŸ”µ S&P500 ULTRA TOP5å¤‰å‹•:")
        for i, (today_stock, yesterday_stock) in enumerate(zip(today_sp500, yesterday_sp500), 1):
            if today_stock != yesterday_stock:
                print(f"  {i}ä½: {yesterday_stock} â†’ {today_stock} ğŸ”„")
            else:
                print(f"  {i}ä½: {today_stock} (å¤‰å‹•ãªã—)")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=== çµ±åˆæ ªä¾¡ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹ ===")
    
    # dataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    output_dir = "data"
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"ğŸ“ {output_dir}ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã—ãŸ")
    
    # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    history = load_history()
    
    # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šNASDAQ100ã®ã¿å®Ÿè¡Œ
    nasdaq_symbols, _ = get_nasdaq100_symbols()
    nasdaq_result = process_stock_data(nasdaq_symbols, "NASDAQ-100")
    
    print(f"\nğŸ” NASDAQ100çµæœã®è©³ç´°:")
    print(f"nasdaq_result = {nasdaq_result}")
    
    # S&P500ã¯ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–
    print("ğŸ”§ S&P500å‡¦ç†ã‚’ä¸€æ™‚çš„ã«ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå•é¡Œèª¿æŸ»ä¸­ï¼‰")
    sp500_result = None
    
    # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
    history = update_history(history, nasdaq_result, sp500_result)
    
    # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    save_history(history)
    
    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°å¤‰å‹•åˆ†æï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    analyze_ranking_changes(history)
    
    # ç¾åœ¨ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ã¾ã¨ã‚ã‚‹
    final_result = {
        "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S UTC"),
        "nasdaq100": nasdaq_result,
        "sp500": sp500_result
    }
    
    # ç¾åœ¨ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
    with open(f"{output_dir}/stock_rankings.json", "w", encoding="utf-8") as f:
        json.dump(final_result, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… çµæœã‚’{output_dir}/stock_rankings.jsonã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    # çµæœã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è¡¨ç¤º
    print("\n" + "="*60)
    print("ğŸ“Š æœ€æ–°ãƒ©ãƒ³ã‚­ãƒ³ã‚°çµæœ")
    print("="*60)
    
    if nasdaq_result:
        print(f"\nğŸŸ¢ NASDAQ-100 (æ›´æ–°æ—¥: {nasdaq_result['last_updated']})")
        print("ğŸ† TOP10:")
        for i, ticker in enumerate(nasdaq_result['top_10'], 1):
            print(f"  {i:2d}. {ticker}")
        print("â­ ULTRA TOP5:")
        for i, ticker in enumerate(nasdaq_result['ultra_top_5'], 1):
            print(f"  {i}. {ticker}")
    
    if sp500_result:
        print(f"\nğŸ”µ S&P 500 (æ›´æ–°æ—¥: {sp500_result['last_updated']})")
        print("ğŸ† TOP10:")
        for i, ticker in enumerate(sp500_result['top_10'], 1):
            print(f"  {i:2d}. {ticker}")
        print("â­ ULTRA TOP5:")
        for i, ticker in enumerate(sp500_result['ultra_top_5'], 1):
            print(f"  {i}. {ticker}")
    
    print("\n" + "="*60)
    print("ğŸ¯ å®Ÿè¡Œå®Œäº†ï¼")
    print(f"ğŸ“š å±¥æ­´ãƒ‡ãƒ¼ã‚¿: {len(history)}æ—¥åˆ†ä¿å­˜æ¸ˆã¿")
    
    return final_result

if __name__ == "__main__":
    result = main()
